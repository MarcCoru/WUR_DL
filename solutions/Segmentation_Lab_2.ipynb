{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df70121156693fe9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Lab 2: Encoder-Decoder Models\n",
    "\n",
    "In this lab, we investigate the U-Net architecture and see two application examples.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/2b/Example_architecture_of_U-Net_for_producing_k_256-by-256_image_masks_for_a_256-by-256_RGB_image.png\" width=\"100%\">\n",
    "\n",
    "Image Wikipedia\n",
    "\n",
    "## Questions\n",
    "\n",
    "* Why does `bilinear=False` build a U-Net with more parameters than `bilinear=False`?\n",
    "\n",
    "#SOLUTIONSTART\n",
    "bilinear=False implements upsampling with transposed convolutions, which introduces additional weights\n",
    "#SOLUTIONEND\n",
    "\n",
    "* U-Nets (and other encoder-decoder models) work very well for medical or remote sensing (satellite) images, but not for classic natural images (natural scenes like cats, dogs, humans, streets). Given their architecture, can you explain why they may be better suited for medical or remote sensing (satellite) images? Think about which inductive biases are encoded in the model architecture.\n",
    "\n",
    "#SOLUTIONSTART\n",
    "In general, U-Nets and encoder-decoder models are used broadly used for medical or remote sensing (satellite) images, due to their inductive biases: Here, relevant features in the images have the same scale. The skip connections in the U-Net implement this intuition natively.\n",
    "#SOLUTIONEND"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca9929ba6df3094",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# U-Net Source Code\n",
    "\n",
    "Let's investigate how a U-Net is concretely implemented in Pytorch.\n",
    "\n",
    "For your projects, you can use existing packages like [`torch_segmentation_models`](https://smp.readthedocs.io/en/latest/quickstart.html) that provide various model implementations using common classification backbones (i.e., encoders):\n",
    "```\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "```\n",
    "\n",
    "But for now, let's investigate a vanilla torch U-Net from [the Pytorch-UNet\n",
    " repository](https://github.com/milesial/Pytorch-UNet/tree/master)\n",
    "\n",
    "**Task**: \n",
    "* Implement the decoder forward pass through the up layers (see #TODO in the forward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48dcf40f3e0f1666",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T16:04:41.270956Z",
     "start_time": "2024-03-22T16:04:41.198787Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#============== some parts of the U-Net model ===============#\n",
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "#=================== Assembling parts to form the network =================#\n",
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x.float())\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        # TODO implement the forward pass of the decoder up layers up2, u3, up4\n",
    "        # x = ...\n",
    "        # x = ---\n",
    "        # x = ...\n",
    "        #SOLUTIONSTART\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        #SOLUTIONEND\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "    \n",
    "model = UNet(3,1, bilinear=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae27fdd56d586e2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Investigating the U-Net Upsampling Mechanism\n",
    "\n",
    "**Question**\n",
    "* How is the upsampling implemented? Check and follow the `bilinear` argument in the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1fed0b5b158d183a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T16:04:51.203926Z",
     "start_time": "2024-03-22T16:04:51.044418Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "print(\"bilinear = False\")\n",
    "print(get_n_params(UNet(3,1, bilinear=False)))\n",
    "\n",
    "print(\"bilinear = True\")\n",
    "print(get_n_params(UNet(3,1, bilinear=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e3061498f8a7a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Application Examples\n",
    "\n",
    "### Example FLAIR Abnormality Segmentation in Brain MRI\n",
    "\n",
    "\"Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm\" [Buda et al., 2019](https://www.sciencedirect.com/science/article/abs/pii/S0010482519301520?via%3Dihub)\n",
    "\n",
    "U-Net implementation in PyTorch for FLAIR abnormality segmentation in brain MRI based on a deep learning segmentation algorithm used in Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm.\n",
    "\n",
    "This code is based on [this TorchHub example](https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce9e7319a32e64ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T16:05:01.377438Z",
     "start_time": "2024-03-22T16:04:59.556814Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
    "\n",
    "# Download an example image\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/mateuszbuda/brain-segmentation-pytorch/raw/master/assets/TCGA_CS_4944.png\", \"TCGA_CS_4944.png\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ccbbceeb31bf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The U-Net model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89f56acb5b34dbf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T16:05:01.383041Z",
     "start_time": "2024-03-22T16:05:01.379758Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6102466216776044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T16:05:02.992248Z",
     "start_time": "2024-03-22T16:05:02.666627Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "m, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model = model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(input_image)\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].set_title(\"input image\")\n",
    "axs[1].imshow(output[0][0])\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].set_title(\"segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63290b8ce8f3a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Explore Model Architecture through Hooks\n",
    "\n",
    "In PyTorch, hook callback functions are mechanisms used to intercept and observe the computation flow during the forward and backward passes of a neural network. They allow you to access and manipulate intermediate outputs, gradients, and parameters of the network at various stages of its execution.\n",
    "\n",
    "Types of Hooks:\n",
    "\n",
    "* Forward Hooks: These hooks are executed during the forward pass of the network, allowing you to access intermediate activations or outputs of each layer before they are passed to the next layer.\n",
    "* Backward Hooks: These hooks are executed during the backward pass, giving you access to gradients of the parameters with respect to the loss function. They are useful for tasks like gradient visualization, gradient-based optimization, or debugging.\n",
    "\n",
    "Implementation:\n",
    "\n",
    "To implement a hook, you define a callback function that specifies what you want to do with the intermediate data or gradients.\n",
    "You then attach this callback function to the desired module or parameter using the register_forward_hook() or register_backward_hook() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c18c8424236a35e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T16:01:17.396509Z",
     "start_time": "2024-03-22T16:01:17.201478Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def forward_hook(module, input, output):\n",
    "    if isinstance(input, tuple):\n",
    "        input = input[0]\n",
    "        \n",
    "    print(f\"Forward pass - module {module} -  Input shape: {input.shape}, Output shape: {output.shape}\")\n",
    "\n",
    "try: # try-catch are mechanisms to handle exceptions. They are here to make sure that the hook is removed even if your hook function throws an error\n",
    "    hook_handle = model.conv.register_forward_hook(forward_hook)\n",
    "    output = model(input_batch)\n",
    "finally: # this code gets executed even if the code above throws an exception\n",
    "    hook_handle.remove() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8deb95bed62045a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T16:05:21.256390Z",
     "start_time": "2024-03-22T16:05:19.484545Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def hook(module, inputs, outputs):\n",
    "    print(inputs[0].shape)\n",
    "    print(outputs.shape)\n",
    "    print(module)\n",
    "    \n",
    "    fig, axs = plt.subplots(4,8, figsize=(3*8,3*4))\n",
    "    #TODO: plot the 32 feature map before the last 1x1 convolution\n",
    "    #SOLUTIONSTART\n",
    "    for i, (inp, ax) in enumerate(zip(inputs[0][0], axs.reshape(-1))):\n",
    "        ax.imshow(inp)\n",
    "        ax.set_title(f\"dim {i+1}\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    #SOLUTIONEND\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(outputs[0,0])\n",
    "    ax.set_title(\"outputs\")\n",
    "try:\n",
    "    hook_handle = model.conv.register_forward_hook(hook)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "finally:\n",
    "    hook_handle.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
